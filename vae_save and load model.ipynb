{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vae latest",
      "provenance": [],
      "authorship_tag": "ABX9TyNieVc/BfI7HwIMwdzYnRiI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JieRou-1007/FYP/blob/master/vae_save%20and%20load%20model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oUqrEkd7uN-",
        "outputId": "059bd4ae-1b51-4f46-8bc7-0f1692ba3d04"
      },
      "source": [
        "!git clone https://github.com/pytorch/examples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'examples' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clV8uKpu-udx",
        "outputId": "4969ce52-81b9-4bb1-c900-4d194d0cb524"
      },
      "source": [
        " from google.colab import drive\r\n",
        " drive.mount('/content/gdrive') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcQbkfyJ7_MH",
        "outputId": "f1130667-9b7e-4c67-939e-564c3670b128"
      },
      "source": [
        "pip install -r /content/examples/vae/requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r /content/examples/vae/requirements.txt (line 1)) (1.7.1+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r /content/examples/vae/requirements.txt (line 2)) (0.8.2+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r /content/examples/vae/requirements.txt (line 3)) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from -r /content/examples/vae/requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->-r /content/examples/vae/requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r /content/examples/vae/requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->-r /content/examples/vae/requirements.txt (line 2)) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN5YfXARWaWU"
      },
      "source": [
        "# check if CUDA is available\r\n",
        "use_cuda = torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxPQzbiUJmDX"
      },
      "source": [
        "def save_ckp(state, is_best, checkpoint_path, best_model_path):\r\n",
        "    \"\"\"\r\n",
        "    state: checkpoint we want to save\r\n",
        "    is_best: is this the best checkpoint; min validation loss\r\n",
        "    checkpoint_path: path to save checkpoint\r\n",
        "    best_model_path: path to save best model\r\n",
        "    \"\"\"\r\n",
        "    f_path = checkpoint_path\r\n",
        "    # save checkpoint data to the path given, checkpoint_path\r\n",
        "    torch.save(state, f_path)\r\n",
        "    # if it is a best model, min validation loss\r\n",
        "    if is_best:\r\n",
        "        best_fpath = best_model_path\r\n",
        "        # copy that checkpoint file to best path given, best_model_path\r\n",
        "        shutil.copyfile(f_path, best_fpath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWPB07E3rl5R"
      },
      "source": [
        "def load_ckp(checkpoint_fpath, model, optimizer):\r\n",
        "    \"\"\"\r\n",
        "    checkpoint_path: path to save checkpoint\r\n",
        "    model: model that we want to load checkpoint parameters into       \r\n",
        "    optimizer: optimizer we defined in previous training\r\n",
        "    \"\"\"\r\n",
        "    # load check point\r\n",
        "    checkpoint = torch.load(checkpoint_fpath)\r\n",
        "    # initialize state_dict from checkpoint to model\r\n",
        "    model.load_state_dict(checkpoint['state_dict'])\r\n",
        "    # initialize optimizer from checkpoint to optimizer\r\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\r\n",
        "    # initialize valid_loss_min from checkpoint to valid_loss_min\r\n",
        "    valid_loss_min = checkpoint['valid_loss_min']\r\n",
        "    # return model, optimizer, epoch value, min validation loss \r\n",
        "    return model, optimizer, checkpoint['epoch'], valid_loss_min"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DldLcnUtCbNx",
        "outputId": "52c00481-61fb-4aa1-c891-0f62e505609e"
      },
      "source": [
        "from __future__ import print_function\r\n",
        "import argparse\r\n",
        "import torch\r\n",
        "import torch.utils.data\r\n",
        "from torch import nn, optim\r\n",
        "from torch.nn import functional as F\r\n",
        "from torchvision import datasets, transforms\r\n",
        "from torchvision.utils import save_image\r\n",
        "import numpy as np\r\n",
        "import shutil\r\n",
        "\r\n",
        "\r\n",
        "parser = argparse.ArgumentParser(description='VAE MNIST Example')\r\n",
        "batch_size = 128\r\n",
        "n_epochs = 2\r\n",
        "seed = 1 \r\n",
        "log_interval = 10\r\n",
        "# parser.add_argument('--batch-size', type=int, default=128, metavar='N',\r\n",
        "#                     help='input batch size for training (default: 128)')\r\n",
        "# parser.add_argument('--epochs', type=int, default=20, metavar='N',\r\n",
        "#                     help='number of epochs to train (default: 10)')\r\n",
        "# parser.add_argument('--no-cuda', action='store_true', default=False,\r\n",
        "#                     help='disables CUDA training')\r\n",
        "# parser.add_argument('--seed', type=int, default=1, metavar='S',\r\n",
        "#                     help='random seed (default: 1)')\r\n",
        "# parser.add_argument('--log-interval', type=int, default=10, metavar='N',\r\n",
        "#                     help='how many batches to wait before logging training status')\r\n",
        "# args = parser.parse_args()\r\n",
        "# args.cuda = not args.no_cuda and torch.cuda.is_available()\r\n",
        "\r\n",
        "torch.manual_seed(seed)\r\n",
        "\r\n",
        "device = torch.device(\"cuda\")\r\n",
        "\r\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} \r\n",
        "\r\n",
        "loaders = {\r\n",
        "  'train': torch.utils.data.DataLoader(\r\n",
        "      datasets.CIFAR10('../data', train=True, download=True,\r\n",
        "                    transform=transforms.ToTensor()),\r\n",
        "      batch_size, shuffle=True, **kwargs),\r\n",
        "  \r\n",
        "  'test' : torch.utils.data.DataLoader(\r\n",
        "      datasets.CIFAR10('../data', train=False, transform=transforms.ToTensor()),\r\n",
        "      batch_size, shuffle=True, **kwargs),\r\n",
        "}\r\n",
        "\r\n",
        "class VAE(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(VAE, self).__init__()\r\n",
        "\r\n",
        "        self.fc1 = nn.Linear(3*32*32, 400)\r\n",
        "        self.fc21 = nn.Linear(400, 20)\r\n",
        "        self.fc22 = nn.Linear(400, 20)\r\n",
        "        self.fc3 = nn.Linear(20, 400)\r\n",
        "        self.fc4 = nn.Linear(400, 3*32*32)\r\n",
        "\r\n",
        "    def encode(self, x):\r\n",
        "        h1 = F.relu(self.fc1(x))\r\n",
        "        return self.fc21(h1), self.fc22(h1)\r\n",
        "\r\n",
        "    def reparameterize(self, mu, logvar):\r\n",
        "        std = torch.exp(0.5*logvar)\r\n",
        "        eps = torch.randn_like(std)\r\n",
        "        return mu + eps*std\r\n",
        "\r\n",
        "    def decode(self, z):\r\n",
        "        h3 = F.relu(self.fc3(z))\r\n",
        "        return torch.sigmoid(self.fc4(h3))\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        mu, logvar = self.encode(x.view(x.size(0), 3*32*32))\r\n",
        "        z = self.reparameterize(mu, logvar)\r\n",
        "        return self.decode(z), mu, logvar\r\n",
        "\r\n",
        "\r\n",
        "model = VAE().to(device)\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\r\n",
        "\r\n",
        "\r\n",
        "# Reconstruction + KL divergence losses summed over all elements and batch\r\n",
        "def loss_function(recon_x, x, mu, logvar):\r\n",
        "    BCE = F.binary_cross_entropy(recon_x, x.view(x.size(0), 3*32*32), reduction='sum')\r\n",
        "\r\n",
        "    # see Appendix B from VAE paper:\r\n",
        "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\r\n",
        "    # https://arxiv.org/abs/1312.6114\r\n",
        "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\r\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\r\n",
        "\r\n",
        "    return BCE + KLD\r\n",
        "\r\n",
        "\r\n",
        "def train(start_epochs, n_epochs, test_loss_min_input, loaders, model, optimizer, criterion, use_cuda, checkpoint_path, best_model_path):\r\n",
        "    test_loss_min = test_loss_min_input \r\n",
        "\r\n",
        "    for epoch in range(start_epochs, n_epochs + 1):\r\n",
        "      model.train()\r\n",
        "      train_loss = 0\r\n",
        "      for batch_idx, (data, _) in enumerate(loaders['train']):\r\n",
        "          # move to GPU\r\n",
        "          if use_cuda:\r\n",
        "              data, _ = data.cuda(), _.cuda()\r\n",
        "          data = data.to(device)\r\n",
        "          optimizer.zero_grad()\r\n",
        "          recon_batch, mu, logvar = model(data)\r\n",
        "          loss = loss_function(recon_batch, data, mu, logvar)\r\n",
        "          loss.backward()\r\n",
        "          train_loss += loss.item()\r\n",
        "          optimizer.step()\r\n",
        "          if batch_idx % log_interval == 0:\r\n",
        "              print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\r\n",
        "                  epoch, batch_idx * len(data), len(train_loader.dataset),\r\n",
        "                  100. * batch_idx / len(train_loader),\r\n",
        "                  loss.item() / len(data)))\r\n",
        "\r\n",
        "      print('====> Epoch: {} Average loss: {:.4f}'.format(\r\n",
        "            epoch, train_loss / len(train_loader.dataset)))\r\n",
        "\r\n",
        "      #test\r\n",
        "      model.eval()\r\n",
        "      test_loss = 0\r\n",
        "      with torch.no_grad():\r\n",
        "          for i, (data, _) in enumerate(loaders['test']):\r\n",
        "              # move to GPU\r\n",
        "              if use_cuda:\r\n",
        "                  data, _ = data.cuda(), _.cuda()\r\n",
        "                  data = data.to(device)\r\n",
        "              recon_batch, mu, logvar = model(data)\r\n",
        "              test_loss += loss_function(recon_batch, data, mu, logvar).item()\r\n",
        "              if i == 0:\r\n",
        "                  n = min(data.size(0), 8)\r\n",
        "                  comparison = torch.cat([data[:n],\r\n",
        "                                        recon_batch.view(batch_size, 3, 32, 32)[:n]])\r\n",
        "                  save_image(comparison.cpu(),\r\n",
        "                          '/content/examples/vae/results/reconstruction_' + str(epoch) + '.png', nrow=n)\r\n",
        "                  \r\n",
        "      checkpoint = {\r\n",
        "              'epoch': epoch + 1,\r\n",
        "              'valid_loss_min': test_loss,\r\n",
        "              'state_dict': model.state_dict(),\r\n",
        "              'optimizer': optimizer.state_dict(),\r\n",
        "          }\r\n",
        "\r\n",
        "      checkpoint_path = './cifar_net{}.pth'.format(epoch)\r\n",
        "      best_model_path = './best.pth'\r\n",
        "      # save checkpoint\r\n",
        "      save_ckp(checkpoint, False, checkpoint_path, best_model_path)\r\n",
        "\r\n",
        "      ## TODO: save the model if validation loss has decreased\r\n",
        "      if test_loss <= test_loss_min:\r\n",
        "          print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(test_loss_min,test_loss))\r\n",
        "          # save checkpoint as best model\r\n",
        "          save_ckp(checkpoint, True, checkpoint_path, best_model_path)\r\n",
        "          test_loss_min = test_loss\r\n",
        "\r\n",
        "      test_loss /= len(test_loader.dataset)\r\n",
        "      print('====> Test set loss: {:.4f}'.format(test_loss))\r\n",
        "\r\n",
        "      with torch.no_grad():\r\n",
        "        sample = torch.randn(64, 20).to(device)\r\n",
        "        sample = model.decode(sample).cpu()\r\n",
        "        save_image(sample.view(64, 3, 32, 32),\r\n",
        "                    '/content/examples/vae/results/sample_' + str(epoch) + '.png')\r\n",
        "      \r\n",
        "    return model\r\n",
        "   \r\n",
        "# PATH = './cifar_net.pth'\r\n",
        "# torch.save(model.state_dict(), PATH)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "uMZe1XN7YAPN",
        "outputId": "bea376c1-81bc-4160-8e31-14971387d575"
      },
      "source": [
        "trained_model = train(1, n_epochs, np.Inf,loaders, model, optimizer, loss_function,use_cuda, './cifar_net.pth', './best.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2152.270508\n",
            "Train Epoch: 1 [1280/50000 (3%)]\tLoss: 2112.378662\n",
            "Train Epoch: 1 [2560/50000 (5%)]\tLoss: 2061.184814\n",
            "Train Epoch: 1 [3840/50000 (8%)]\tLoss: 2030.074097\n",
            "Train Epoch: 1 [5120/50000 (10%)]\tLoss: 2028.063354\n",
            "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 1987.913208\n",
            "Train Epoch: 1 [7680/50000 (15%)]\tLoss: 1976.817505\n",
            "Train Epoch: 1 [8960/50000 (18%)]\tLoss: 1968.977783\n",
            "Train Epoch: 1 [10240/50000 (20%)]\tLoss: 1984.599121\n",
            "Train Epoch: 1 [11520/50000 (23%)]\tLoss: 1967.367432\n",
            "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1949.873535\n",
            "Train Epoch: 1 [14080/50000 (28%)]\tLoss: 1948.278809\n",
            "Train Epoch: 1 [15360/50000 (31%)]\tLoss: 1938.056030\n",
            "Train Epoch: 1 [16640/50000 (33%)]\tLoss: 1947.667114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-0fa17346d6d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./cifar_net.pth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./best.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-54-a69b83721191>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(start_epochs, n_epochs, test_loss_min_input, loaders, model, optimizer, criterion, use_cuda, checkpoint_path, best_model_path)\u001b[0m\n\u001b[1;32m     98\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m           \u001b[0;31m# move to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux1BWThiTK4H"
      },
      "source": [
        "# load model\r\n",
        "model = VAE()\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\r\n",
        "criterion = loss_function\r\n",
        "# define checkpoint saved path\r\n",
        "ckp_path = \"/content/cifar_net2.pth\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAQ380QBTfcT"
      },
      "source": [
        "# load checkpoint\r\n",
        "model, optimizer, start_epoch, valid_loss_min = load_ckp(ckp_path, model, optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ps8zWs8hT7la",
        "outputId": "e73d37f8-40ab-4488-91f9-28289c95ca15"
      },
      "source": [
        "print(\"model = \", model)\r\n",
        "print(\"optimizer = \", optimizer)\r\n",
        "print(\"start_epoch = \", start_epoch)\r\n",
        "print(\"valid_loss_min = \", valid_loss_min)\r\n",
        "print(\"valid_loss_min = {:.6f}\".format(valid_loss_min))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model =  VAE(\n",
            "  (fc1): Linear(in_features=3072, out_features=400, bias=True)\n",
            "  (fc21): Linear(in_features=400, out_features=20, bias=True)\n",
            "  (fc22): Linear(in_features=400, out_features=20, bias=True)\n",
            "  (fc3): Linear(in_features=20, out_features=400, bias=True)\n",
            "  (fc4): Linear(in_features=400, out_features=3072, bias=True)\n",
            ")\n",
            "optimizer =  Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.001\n",
            "    weight_decay: 0\n",
            ")\n",
            "start_epoch =  3\n",
            "valid_loss_min =  18634078.7734375\n",
            "valid_loss_min = 18634078.773438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1P1vKnluKaTG",
        "outputId": "f50c5ef5-a78b-4d72-eb9b-c9da703bba38"
      },
      "source": [
        "trained_model = train(start_epoch, 6, valid_loss_min, loaders, model, optimizer, criterion, use_cuda, \"/content/cifar_net2.pth\", \"/content/best.pth\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1850.973267\n",
            "Train Epoch: 3 [1280/50000 (3%)]\tLoss: 1859.375488\n",
            "Train Epoch: 3 [2560/50000 (5%)]\tLoss: 1843.817871\n",
            "Train Epoch: 3 [3840/50000 (8%)]\tLoss: 1852.000366\n",
            "Train Epoch: 3 [5120/50000 (10%)]\tLoss: 1861.786377\n",
            "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 1824.171265\n",
            "Train Epoch: 3 [7680/50000 (15%)]\tLoss: 1881.344849\n",
            "Train Epoch: 3 [8960/50000 (18%)]\tLoss: 1871.249268\n",
            "Train Epoch: 3 [10240/50000 (20%)]\tLoss: 1894.118896\n",
            "Train Epoch: 3 [11520/50000 (23%)]\tLoss: 1833.054810\n",
            "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1873.446289\n",
            "Train Epoch: 3 [14080/50000 (28%)]\tLoss: 1869.067383\n",
            "Train Epoch: 3 [15360/50000 (31%)]\tLoss: 1859.456543\n",
            "Train Epoch: 3 [16640/50000 (33%)]\tLoss: 1824.520264\n",
            "Train Epoch: 3 [17920/50000 (36%)]\tLoss: 1849.226074\n",
            "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 1872.960205\n",
            "Train Epoch: 3 [20480/50000 (41%)]\tLoss: 1872.426025\n",
            "Train Epoch: 3 [21760/50000 (43%)]\tLoss: 1851.970215\n",
            "Train Epoch: 3 [23040/50000 (46%)]\tLoss: 1839.107910\n",
            "Train Epoch: 3 [24320/50000 (49%)]\tLoss: 1897.563721\n",
            "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1853.921753\n",
            "Train Epoch: 3 [26880/50000 (54%)]\tLoss: 1864.693115\n",
            "Train Epoch: 3 [28160/50000 (56%)]\tLoss: 1857.268555\n",
            "Train Epoch: 3 [29440/50000 (59%)]\tLoss: 1880.520386\n",
            "Train Epoch: 3 [30720/50000 (61%)]\tLoss: 1841.713745\n",
            "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1854.912476\n",
            "Train Epoch: 3 [33280/50000 (66%)]\tLoss: 1849.458374\n",
            "Train Epoch: 3 [34560/50000 (69%)]\tLoss: 1848.681396\n",
            "Train Epoch: 3 [35840/50000 (72%)]\tLoss: 1842.657227\n",
            "Train Epoch: 3 [37120/50000 (74%)]\tLoss: 1876.067139\n",
            "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1828.835938\n",
            "Train Epoch: 3 [39680/50000 (79%)]\tLoss: 1888.742920\n",
            "Train Epoch: 3 [40960/50000 (82%)]\tLoss: 1824.626709\n",
            "Train Epoch: 3 [42240/50000 (84%)]\tLoss: 1871.816650\n",
            "Train Epoch: 3 [43520/50000 (87%)]\tLoss: 1868.063232\n",
            "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 1847.380493\n",
            "Train Epoch: 3 [46080/50000 (92%)]\tLoss: 1868.067505\n",
            "Train Epoch: 3 [47360/50000 (95%)]\tLoss: 1876.888916\n",
            "Train Epoch: 3 [48640/50000 (97%)]\tLoss: 1894.413208\n",
            "Train Epoch: 3 [31200/50000 (100%)]\tLoss: 1864.264453\n",
            "====> Epoch: 3 Average loss: 1856.9177\n",
            "Validation loss decreased (18634078.773438 --> 18575209.476562).  Saving model ...\n",
            "====> Test set loss: 1857.5209\n",
            "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1861.119751\n",
            "Train Epoch: 4 [1280/50000 (3%)]\tLoss: 1839.571167\n",
            "Train Epoch: 4 [2560/50000 (5%)]\tLoss: 1852.287598\n",
            "Train Epoch: 4 [3840/50000 (8%)]\tLoss: 1855.262207\n",
            "Train Epoch: 4 [5120/50000 (10%)]\tLoss: 1878.682739\n",
            "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 1851.614868\n",
            "Train Epoch: 4 [7680/50000 (15%)]\tLoss: 1836.818848\n",
            "Train Epoch: 4 [8960/50000 (18%)]\tLoss: 1863.251099\n",
            "Train Epoch: 4 [10240/50000 (20%)]\tLoss: 1869.406372\n",
            "Train Epoch: 4 [11520/50000 (23%)]\tLoss: 1831.290527\n",
            "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1835.660522\n",
            "Train Epoch: 4 [14080/50000 (28%)]\tLoss: 1870.869751\n",
            "Train Epoch: 4 [15360/50000 (31%)]\tLoss: 1833.398438\n",
            "Train Epoch: 4 [16640/50000 (33%)]\tLoss: 1848.686401\n",
            "Train Epoch: 4 [17920/50000 (36%)]\tLoss: 1875.637451\n",
            "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 1856.755981\n",
            "Train Epoch: 4 [20480/50000 (41%)]\tLoss: 1889.860229\n",
            "Train Epoch: 4 [21760/50000 (43%)]\tLoss: 1873.879150\n",
            "Train Epoch: 4 [23040/50000 (46%)]\tLoss: 1880.598145\n",
            "Train Epoch: 4 [24320/50000 (49%)]\tLoss: 1864.824097\n",
            "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1860.290283\n",
            "Train Epoch: 4 [26880/50000 (54%)]\tLoss: 1810.455566\n",
            "Train Epoch: 4 [28160/50000 (56%)]\tLoss: 1843.033447\n",
            "Train Epoch: 4 [29440/50000 (59%)]\tLoss: 1892.298706\n",
            "Train Epoch: 4 [30720/50000 (61%)]\tLoss: 1859.348755\n",
            "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 1862.949585\n",
            "Train Epoch: 4 [33280/50000 (66%)]\tLoss: 1857.673218\n",
            "Train Epoch: 4 [34560/50000 (69%)]\tLoss: 1856.601685\n",
            "Train Epoch: 4 [35840/50000 (72%)]\tLoss: 1846.905762\n",
            "Train Epoch: 4 [37120/50000 (74%)]\tLoss: 1871.891113\n",
            "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1869.648071\n",
            "Train Epoch: 4 [39680/50000 (79%)]\tLoss: 1846.383423\n",
            "Train Epoch: 4 [40960/50000 (82%)]\tLoss: 1860.059814\n",
            "Train Epoch: 4 [42240/50000 (84%)]\tLoss: 1880.810791\n",
            "Train Epoch: 4 [43520/50000 (87%)]\tLoss: 1868.408325\n",
            "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 1878.671021\n",
            "Train Epoch: 4 [46080/50000 (92%)]\tLoss: 1839.265869\n",
            "Train Epoch: 4 [47360/50000 (95%)]\tLoss: 1822.801514\n",
            "Train Epoch: 4 [48640/50000 (97%)]\tLoss: 1846.579956\n",
            "Train Epoch: 4 [31200/50000 (100%)]\tLoss: 1847.666992\n",
            "====> Epoch: 4 Average loss: 1853.0514\n",
            "Validation loss decreased (18575209.476562 --> 18572386.859375).  Saving model ...\n",
            "====> Test set loss: 1857.2387\n",
            "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1826.964966\n",
            "Train Epoch: 5 [1280/50000 (3%)]\tLoss: 1860.270386\n",
            "Train Epoch: 5 [2560/50000 (5%)]\tLoss: 1865.352783\n",
            "Train Epoch: 5 [3840/50000 (8%)]\tLoss: 1844.674683\n",
            "Train Epoch: 5 [5120/50000 (10%)]\tLoss: 1838.650635\n",
            "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 1824.376343\n",
            "Train Epoch: 5 [7680/50000 (15%)]\tLoss: 1887.534424\n",
            "Train Epoch: 5 [8960/50000 (18%)]\tLoss: 1856.292358\n",
            "Train Epoch: 5 [10240/50000 (20%)]\tLoss: 1875.623169\n",
            "Train Epoch: 5 [11520/50000 (23%)]\tLoss: 1854.788940\n",
            "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 1865.616211\n",
            "Train Epoch: 5 [14080/50000 (28%)]\tLoss: 1866.187866\n",
            "Train Epoch: 5 [15360/50000 (31%)]\tLoss: 1863.795654\n",
            "Train Epoch: 5 [16640/50000 (33%)]\tLoss: 1868.189941\n",
            "Train Epoch: 5 [17920/50000 (36%)]\tLoss: 1850.868286\n",
            "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 1831.624634\n",
            "Train Epoch: 5 [20480/50000 (41%)]\tLoss: 1829.656250\n",
            "Train Epoch: 5 [21760/50000 (43%)]\tLoss: 1863.442261\n",
            "Train Epoch: 5 [23040/50000 (46%)]\tLoss: 1813.671631\n",
            "Train Epoch: 5 [24320/50000 (49%)]\tLoss: 1823.859741\n",
            "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1870.283203\n",
            "Train Epoch: 5 [26880/50000 (54%)]\tLoss: 1836.334351\n",
            "Train Epoch: 5 [28160/50000 (56%)]\tLoss: 1854.798706\n",
            "Train Epoch: 5 [29440/50000 (59%)]\tLoss: 1863.888306\n",
            "Train Epoch: 5 [30720/50000 (61%)]\tLoss: 1836.234497\n",
            "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 1849.409668\n",
            "Train Epoch: 5 [33280/50000 (66%)]\tLoss: 1873.838867\n",
            "Train Epoch: 5 [34560/50000 (69%)]\tLoss: 1806.073486\n",
            "Train Epoch: 5 [35840/50000 (72%)]\tLoss: 1866.061768\n",
            "Train Epoch: 5 [37120/50000 (74%)]\tLoss: 1866.421509\n",
            "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 1874.810303\n",
            "Train Epoch: 5 [39680/50000 (79%)]\tLoss: 1827.089722\n",
            "Train Epoch: 5 [40960/50000 (82%)]\tLoss: 1842.123535\n",
            "Train Epoch: 5 [42240/50000 (84%)]\tLoss: 1854.050537\n",
            "Train Epoch: 5 [43520/50000 (87%)]\tLoss: 1852.946167\n",
            "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 1850.113403\n",
            "Train Epoch: 5 [46080/50000 (92%)]\tLoss: 1850.332397\n",
            "Train Epoch: 5 [47360/50000 (95%)]\tLoss: 1841.139526\n",
            "Train Epoch: 5 [48640/50000 (97%)]\tLoss: 1833.724854\n",
            "Train Epoch: 5 [31200/50000 (100%)]\tLoss: 1869.466406\n",
            "====> Epoch: 5 Average loss: 1850.1726\n",
            "Validation loss decreased (18572386.859375 --> 18542222.025391).  Saving model ...\n",
            "====> Test set loss: 1854.2222\n",
            "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1856.231323\n",
            "Train Epoch: 6 [1280/50000 (3%)]\tLoss: 1873.730591\n",
            "Train Epoch: 6 [2560/50000 (5%)]\tLoss: 1858.175293\n",
            "Train Epoch: 6 [3840/50000 (8%)]\tLoss: 1863.179199\n",
            "Train Epoch: 6 [5120/50000 (10%)]\tLoss: 1846.849365\n",
            "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 1826.594482\n",
            "Train Epoch: 6 [7680/50000 (15%)]\tLoss: 1856.171509\n",
            "Train Epoch: 6 [8960/50000 (18%)]\tLoss: 1861.483032\n",
            "Train Epoch: 6 [10240/50000 (20%)]\tLoss: 1842.420288\n",
            "Train Epoch: 6 [11520/50000 (23%)]\tLoss: 1850.678467\n",
            "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 1833.594971\n",
            "Train Epoch: 6 [14080/50000 (28%)]\tLoss: 1839.302124\n",
            "Train Epoch: 6 [15360/50000 (31%)]\tLoss: 1847.807007\n",
            "Train Epoch: 6 [16640/50000 (33%)]\tLoss: 1867.466675\n",
            "Train Epoch: 6 [17920/50000 (36%)]\tLoss: 1838.762329\n",
            "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 1860.078491\n",
            "Train Epoch: 6 [20480/50000 (41%)]\tLoss: 1886.867432\n",
            "Train Epoch: 6 [21760/50000 (43%)]\tLoss: 1827.816162\n",
            "Train Epoch: 6 [23040/50000 (46%)]\tLoss: 1814.021118\n",
            "Train Epoch: 6 [24320/50000 (49%)]\tLoss: 1829.964600\n",
            "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 1872.972534\n",
            "Train Epoch: 6 [26880/50000 (54%)]\tLoss: 1854.848999\n",
            "Train Epoch: 6 [28160/50000 (56%)]\tLoss: 1872.423462\n",
            "Train Epoch: 6 [29440/50000 (59%)]\tLoss: 1842.706543\n",
            "Train Epoch: 6 [30720/50000 (61%)]\tLoss: 1840.736938\n",
            "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 1827.430420\n",
            "Train Epoch: 6 [33280/50000 (66%)]\tLoss: 1852.226562\n",
            "Train Epoch: 6 [34560/50000 (69%)]\tLoss: 1859.105713\n",
            "Train Epoch: 6 [35840/50000 (72%)]\tLoss: 1841.891846\n",
            "Train Epoch: 6 [37120/50000 (74%)]\tLoss: 1839.818115\n",
            "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 1846.490356\n",
            "Train Epoch: 6 [39680/50000 (79%)]\tLoss: 1846.688477\n",
            "Train Epoch: 6 [40960/50000 (82%)]\tLoss: 1886.779541\n",
            "Train Epoch: 6 [42240/50000 (84%)]\tLoss: 1802.180420\n",
            "Train Epoch: 6 [43520/50000 (87%)]\tLoss: 1844.327759\n",
            "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 1862.345459\n",
            "Train Epoch: 6 [46080/50000 (92%)]\tLoss: 1858.289795\n",
            "Train Epoch: 6 [47360/50000 (95%)]\tLoss: 1851.396118\n",
            "Train Epoch: 6 [48640/50000 (97%)]\tLoss: 1832.279907\n",
            "Train Epoch: 6 [31200/50000 (100%)]\tLoss: 1849.519531\n",
            "====> Epoch: 6 Average loss: 1848.2565\n",
            "Validation loss decreased (18542222.025391 --> 18537562.636719).  Saving model ...\n",
            "====> Test set loss: 1853.7563\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjOd51-s8F52"
      },
      "source": [
        "!python /content/examples/vae/main.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaV5FdcHdD26"
      },
      "source": [
        "from __future__ import print_function\r\n",
        "import argparse\r\n",
        "import torch\r\n",
        "import torch.utils.data\r\n",
        "from torch import nn, optim\r\n",
        "from torch.nn import functional as F\r\n",
        "from torchvision import datasets, transforms\r\n",
        "from torchvision.utils import save_image\r\n",
        "\r\n",
        "class VAE(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(VAE, self).__init__()\r\n",
        "\r\n",
        "        self.fc1 = nn.Linear(3*32*32, 400)\r\n",
        "        self.fc21 = nn.Linear(400, 20)\r\n",
        "        self.fc22 = nn.Linear(400, 20)\r\n",
        "        self.fc3 = nn.Linear(20, 400)\r\n",
        "        self.fc4 = nn.Linear(400, 3*32*32)\r\n",
        "\r\n",
        "    def encode(self, x):\r\n",
        "        h1 = F.relu(self.fc1(x))\r\n",
        "        return self.fc21(h1), self.fc22(h1)\r\n",
        "\r\n",
        "    def reparameterize(self, mu, logvar):\r\n",
        "        std = torch.exp(0.5*logvar)\r\n",
        "        eps = torch.randn_like(std)\r\n",
        "        return mu + eps*std\r\n",
        "\r\n",
        "    def decode(self, z):\r\n",
        "        h3 = F.relu(self.fc3(z))\r\n",
        "        return torch.sigmoid(self.fc4(h3))\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        mu, logvar = self.encode(x.view(x.size(0), 3*32*32))\r\n",
        "        z = self.reparameterize(mu, logvar)\r\n",
        "        return self.decode(z), mu, logvar\r\n",
        "\r\n",
        "device = torch.device(\"cuda\")\r\n",
        "model = VAE().to(device)\r\n",
        "# model.load_state_dict(torch.load('/content/cifar_net.pth'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ruw9buCr5HC"
      },
      "source": [
        "ckp_path = \"/content/cifar_net2.pth\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4cmxDrcraWX"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oDltCvhsAlj"
      },
      "source": [
        "model, optimizer, start_epoch, valid_loss_min = load_ckp(ckp_path, model, optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c7ZjUM5wYu4",
        "outputId": "f21f3658-eb56-413a-9ab2-84817c01217f"
      },
      "source": [
        "print(\"model = \", model)\r\n",
        "print(\"optimizer = \", optimizer)\r\n",
        "print(\"start_epoch = \", start_epoch)\r\n",
        "print(\"valid_loss_min = \", valid_loss_min)\r\n",
        "print(\"valid_loss_min = {:.6f}\".format(valid_loss_min))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model =  VAE(\n",
            "  (fc1): Linear(in_features=3072, out_features=400, bias=True)\n",
            "  (fc21): Linear(in_features=400, out_features=20, bias=True)\n",
            "  (fc22): Linear(in_features=400, out_features=20, bias=True)\n",
            "  (fc3): Linear(in_features=20, out_features=400, bias=True)\n",
            "  (fc4): Linear(in_features=400, out_features=3072, bias=True)\n",
            ")\n",
            "optimizer =  Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.001\n",
            "    weight_decay: 0\n",
            ")\n",
            "start_epoch =  2\n",
            "valid_loss_min =  1863.40787734375\n",
            "valid_loss_min = 1863.407877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "ioe5V68Swlmo",
        "outputId": "2a2187c8-3743-4f2b-dc7e-a6d9bbd5e66d"
      },
      "source": [
        "trained_model = train(start_epoch, 6, valid_loss_min, loaders, model, optimizer, criterion, use_cuda, \"./checkpoint/current_checkpoint.pt\", \"./best_model/best_model.pt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-d1b6cdc8f43d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./checkpoint/current_checkpoint.pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./best_model/best_model.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsu0AV0IsS2S"
      },
      "source": [
        "test_loader = torch.utils.data.DataLoader(\r\n",
        "    datasets.CIFAR10('../data', train=False, transform=transforms.ToTensor()),\r\n",
        "    batch_size=128, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "mTBX1zo3swcp",
        "outputId": "2bbbbb10-a356-463e-c54b-a259dc98c63c"
      },
      "source": [
        "output = model(test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-06fdc7a5d3b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-de6b51a095ab>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreparameterize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'view'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "tbKSmyhVmsoC",
        "outputId": "0beebb2a-1184-44a9-fcbe-52d1e597fdae"
      },
      "source": [
        "device = torch.device(\"cuda\")\r\n",
        "\r\n",
        "with torch.no_grad():\r\n",
        "        sample = torch.randn(64, 20).to(device)\r\n",
        "        sample = model.decode(sample).cpu()\r\n",
        "        save_image(sample.view(64, 1,32 , 32),\r\n",
        "                    '/content/sample_' + str(epoch) + '.png')\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-f537df201285>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         save_image(sample.view(64, 1,32 , 32),\n\u001b[0m\u001b[1;32m      7\u001b[0m                     '/content/sample_' + str(epoch) + '.png')\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[64, 1, 32, 32]' is invalid for input of size 196608"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cRgH79jvHPC"
      },
      "source": [
        "model.eval()\r\n",
        "test_loss = 0\r\n",
        "with torch.no_grad():\r\n",
        "    for i, (data, _) in enumerate(test_loader):\r\n",
        "        data = data.to(device)\r\n",
        "        recon_batch, mu, logvar = model(data)\r\n",
        "      #  test_loss += loss_function(recon_batch, data, mu, logvar).item()\r\n",
        "        if i == 0:\r\n",
        "            n = min(data.size(0), 1)\r\n",
        "            comparison = recon_batch.view(128, 3, 32, 32)[:n]\r\n",
        "            save_image(comparison.cpu(),\r\n",
        "                      '/content/try' + str(2) + '.png', nrow=n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2VsgkKUbJTp",
        "outputId": "173a0861-f297-4704-8cc9-d134c41f802d"
      },
      "source": [
        "pip install ipdb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipdb\n",
            "  Downloading https://files.pythonhosted.org/packages/44/8c/76b33b115f4f2c090e2809a0247fe777eb3832f9d606479bf0139b29ca2c/ipdb-0.13.4.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from ipdb) (53.0.0)\n",
            "Requirement already satisfied: ipython>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from ipdb) (5.5.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.1.0->ipdb) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.1.0->ipdb) (5.0.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=5.1.0->ipdb) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.1.0->ipdb) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=5.1.0->ipdb) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=5.1.0->ipdb) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=5.1.0->ipdb) (2.6.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython>=5.1.0->ipdb) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.1.0->ipdb) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.1.0->ipdb) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.1.0->ipdb) (1.15.0)\n",
            "Building wheels for collected packages: ipdb\n",
            "  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipdb: filename=ipdb-0.13.4-cp37-none-any.whl size=10973 sha256=2676474af015f11d7748824b421f5ba55a32797bf36b4a7b387ce0f285bbd692\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/51/e4/c91c61e3481a1a967beb18c4ea7a2b138a63cce94170b2e206\n",
            "Successfully built ipdb\n",
            "Installing collected packages: ipdb\n",
            "Successfully installed ipdb-0.13.4\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}